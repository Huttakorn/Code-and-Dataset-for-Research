{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#To use this script, provide the path to a zip file containing PDF files and a set of additional stopwords if needed. The script will generate and display a word cloud from the bigrams extracted from the PDFs.\n",
        "\n",
        "# Install necessary libraries\n",
        "pip install PyMuPDF wordcloud matplotlib nltk\n",
        "\n",
        "import zipfile  # Import the zipfile module to work with zip files\n",
        "import os  # Import the os module for file and directory operations\n",
        "import fitz  # PyMuPDF: Import the fitz module to work with PDF files\n",
        "from wordcloud import WordCloud  # Import WordCloud from the wordcloud module\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting the word cloud\n",
        "from nltk.util import bigrams  # Import bigrams utility from nltk\n",
        "from nltk import FreqDist  # Import FreqDist from nltk for frequency distribution\n",
        "from nltk.tokenize import word_tokenize  # Import word_tokenize from nltk for tokenizing words\n",
        "import nltk  # Import the nltk module\n",
        "import shutil  # Import the shutil module for file and directory operations\n",
        "from nltk.corpus import stopwords  # Import stopwords from nltk corpus\n",
        "\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def bigram_wordcloud(zip_path, additional_stopwords=None):\n",
        "    # Step 1: Extract all PDF files from the zip file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract all files into a temporary directory\n",
        "        temp_dir = \"./temp_pdf_extraction\"\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "        # Find all PDF files extracted\n",
        "        pdf_files = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.endswith('.pdf')]\n",
        "\n",
        "    # Step 2: Extract text from each PDF file\n",
        "    combined_text = \"\"\n",
        "    for pdf_file in pdf_files:\n",
        "        with fitz.open(pdf_file) as doc:\n",
        "            for page in doc:\n",
        "                combined_text += page.get_text()\n",
        "    all_text = combined_text.lower()\n",
        "\n",
        "    # Clean up the temporary directory more robustly\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    # Step 3: Preprocess text for bigrams\n",
        "    # Load the default set of stop words from NLTK\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Extend the stop words list with any additional stop words provided\n",
        "    if additional_stopwords:\n",
        "        stop_words.update(additional_stopwords)\n",
        "\n",
        "    # Tokenize the text and remove stop words\n",
        "    tokens = [word for word in word_tokenize(all_text.lower()) if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    # Generate bigrams\n",
        "    bg = bigrams(tokens)\n",
        "\n",
        "    # Compute frequency distribution of bigrams\n",
        "    bg_freq = FreqDist(bg)\n",
        "\n",
        "    # Sort bigrams by frequency and select top 100\n",
        "    top_bigrams = bg_freq.most_common(100)\n",
        "\n",
        "    # Convert frequency distribution to a dictionary with bigram strings as keys\n",
        "    bg_freq_dict = {' '.join(k): v for k, v in top_bigrams}\n",
        "\n",
        "    # Step 4: Generate a word cloud from bigrams\n",
        "    wordcloud = WordCloud(\n",
        "        width=1000, height=1000,\n",
        "        max_words=100,\n",
        "        background_color='white',\n",
        "        font_path='font_path',\n",
        "        min_font_size=10\n",
        "    ).generate_from_frequencies(bg_freq_dict)\n",
        "\n",
        "    # Display the generated word cloud\n",
        "    plt.figure(figsize=(8, 8), facecolor=None)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the word frequencies in the word cloud\n",
        "    print(wordcloud.words_)\n",
        "\n",
        "# Noted:\n",
        "# additional_stopwords = {'exampleword1', 'exampleword2'}"
      ],
      "metadata": {
        "id": "3rWdvu7WuFne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}