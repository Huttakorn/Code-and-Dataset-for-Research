{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#To use this script, provide the path to a zip file containing PDF files and a list of additional stopwords if needed. The script will generate and display a word cloud from the text extracted from the PDFs.\n",
        "\n",
        "# Install necessary libraries\n",
        "pip install PyMuPDF wordcloud matplotlib\n",
        "\n",
        "import zipfile  # Import the zipfile module to work with zip files\n",
        "import os  # Import the os module for file and directory operations\n",
        "import fitz  # PyMuPDF: Import the fitz module to work with PDF files\n",
        "from wordcloud import WordCloud, STOPWORDS  # Import WordCloud and STOPWORDS from the wordcloud module\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting the word cloud\n",
        "import shutil  # Import the shutil module for file and directory operations\n",
        "import re  # Import the regular expressions module\n",
        "\n",
        "def unigram_wordcloud(zip_path, additional_stopwords=None):\n",
        "    # Step 1: Extract all PDF files from the zip file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract all files into a temporary directory\n",
        "        temp_dir = \"./temp_pdf_extraction\"\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "        # Find all PDF files extracted\n",
        "        pdf_files = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.endswith('.pdf')]\n",
        "\n",
        "    # Step 2: Extract text from each PDF file\n",
        "    combined_text = \"\"\n",
        "    for pdf_file in pdf_files:\n",
        "        with fitz.open(pdf_file) as doc:\n",
        "            for page in doc:\n",
        "                combined_text += page.get_text()\n",
        "    all_text = combined_text.lower()\n",
        "\n",
        "    # Clean up the temporary directory\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    # Step 3: Generate a word cloud from the combined text\n",
        "    # Set up the stopwords\n",
        "    stopwords = set(STOPWORDS)\n",
        "    stopwords.update(additional_stopwords)\n",
        "\n",
        "    # Generate the word cloud\n",
        "    wordcloud = WordCloud(\n",
        "        width=1000, height=1000,\n",
        "        max_words=100,\n",
        "        background_color='white',\n",
        "        stopwords=stopwords,\n",
        "        font_path='font_path',\n",
        "        min_font_size=10\n",
        "    ).generate(all_text)\n",
        "\n",
        "    # Display the generated word cloud\n",
        "    plt.figure(figsize=(8, 8), facecolor=None)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the word frequencies in the word cloud\n",
        "    print(wordcloud.words_)\n",
        "\n",
        "    # Noted:\n",
        "    # additional_stopwords = ['exampleword1', 'exampleword2']"
      ],
      "metadata": {
        "id": "Fe1M-LIbs5P1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}